{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/holywater2/.local/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "#\n",
    "# Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n",
    "# SPDX-License-Identifier: Apache-2.0\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from dgllife.data import TencentAlchemyDataset\n",
    "from dgllife.utils import EarlyStopping, Meter\n",
    "\n",
    "# from utils import set_random_seed, collate_molgraphs, load_model\n",
    "\n",
    "def regress(args, model, bg):\n",
    "    bg = bg.to(args['device'])\n",
    "    if args['model'] == 'MPNN':\n",
    "        h = bg.ndata.pop('n_feat')\n",
    "        e = bg.edata.pop('e_feat')\n",
    "        h, e = h.to(args['device']), e.to(args['device'])\n",
    "        return model(bg, h, e)\n",
    "    elif args['model'] in ['SchNet', 'MGCN']:\n",
    "        node_types = bg.ndata.pop('node_type')\n",
    "        edge_distances = bg.edata.pop('distance')\n",
    "        node_types, edge_distances = node_types.to(args['device']), \\\n",
    "                                     edge_distances.to(args['device'])\n",
    "        return model(bg, node_types, edge_distances)\n",
    "\n",
    "def run_a_train_epoch(args, epoch, model, data_loader,\n",
    "                      loss_criterion, optimizer):\n",
    "    model.train()\n",
    "    train_meter = Meter()\n",
    "    for batch_id, batch_data in enumerate(data_loader):\n",
    "        smiles, bg, labels = batch_data\n",
    "        labels = labels.to(args['device'])\n",
    "        prediction = regress(args, model, bg)\n",
    "        loss = (loss_criterion(prediction, labels)).mean()\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_meter.update(prediction, labels)\n",
    "    total_score = np.mean(train_meter.compute_metric(args['metric_name']))\n",
    "    print('epoch {:d}/{:d}, training {} {:.4f}'.format(\n",
    "        epoch + 1, args['num_epochs'], args['metric_name'], total_score))\n",
    "\n",
    "def run_an_eval_epoch(args, model, data_loader):\n",
    "    model.eval()\n",
    "    eval_meter = Meter()\n",
    "    with torch.no_grad():\n",
    "        for batch_id, batch_data in enumerate(data_loader):\n",
    "            smiles, bg, labels = batch_data\n",
    "            labels = labels.to(args['device'])\n",
    "            prediction = regress(args, model, bg)\n",
    "            eval_meter.update(prediction, labels)\n",
    "        total_score = np.mean(eval_meter.compute_metric(args['metric_name']))\n",
    "    return total_score\n",
    "\n",
    "def main(args):\n",
    "    args['device'] = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "    set_random_seed(args['random_seed'])\n",
    "\n",
    "    train_set = TencentAlchemyDataset(mode='dev')\n",
    "    val_set = TencentAlchemyDataset(mode='valid')\n",
    "\n",
    "    train_loader = DataLoader(dataset=train_set,\n",
    "                              batch_size=args['batch_size'],\n",
    "                              shuffle=True,\n",
    "                              collate_fn=collate_molgraphs)\n",
    "    val_loader = DataLoader(dataset=val_set,\n",
    "                            batch_size=args['batch_size'],\n",
    "                            collate_fn=collate_molgraphs)\n",
    "\n",
    "    model = load_model(args)\n",
    "    loss_fn = nn.MSELoss(reduction='none')\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=args['lr'],\n",
    "                                 weight_decay=args['weight_decay'])\n",
    "    stopper = EarlyStopping(mode=args['mode'], patience=args['patience'])\n",
    "    model.to(args['device'])\n",
    "\n",
    "    for epoch in range(args['num_epochs']):\n",
    "        # Train\n",
    "        run_a_train_epoch(args, epoch, model, train_loader, loss_fn, optimizer)\n",
    "\n",
    "        # Validation and early stop\n",
    "        val_score = run_an_eval_epoch(args, model, val_loader)\n",
    "        early_stop = stopper.step(val_score, model)\n",
    "        print('epoch {:d}/{:d}, validation {} {:.4f}, best validation {} {:.4f}'.format(\n",
    "            epoch + 1, args['num_epochs'], args['metric_name'], val_score,\n",
    "            args['metric_name'], stopper.best_score))\n",
    "\n",
    "        if early_stop:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/compuworks/anaconda3/envs/alignn/lib/python3.8/site-packages/dgl/data/graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.\n",
      "  dgl_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99776 loaded!\n",
      "3951 loaded!\n"
     ]
    }
   ],
   "source": [
    "train_set = TencentAlchemyDataset(mode='dev')\n",
    "val_set = TencentAlchemyDataset(mode='valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'e_feat': tensor([[0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [0., 1., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [0., 1., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [0., 0., 1., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [0., 1., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [1., 0., 0., 0., 0.]]), 'distance': tensor([[2.6850],\n",
       "        [2.8703],\n",
       "        [1.8600],\n",
       "        [3.7774],\n",
       "        [1.5204],\n",
       "        [2.6930],\n",
       "        [1.4036],\n",
       "        [2.4027],\n",
       "        [2.9459],\n",
       "        [2.6850],\n",
       "        [2.6267],\n",
       "        [1.4467],\n",
       "        [3.6878],\n",
       "        [3.9940],\n",
       "        [2.5189],\n",
       "        [2.9307],\n",
       "        [3.6952],\n",
       "        [3.4361],\n",
       "        [2.8703],\n",
       "        [2.6267],\n",
       "        [1.8016],\n",
       "        [5.0985],\n",
       "        [3.4200],\n",
       "        [2.6351],\n",
       "        [4.0598],\n",
       "        [4.9921],\n",
       "        [4.8719],\n",
       "        [1.8600],\n",
       "        [1.4467],\n",
       "        [1.8016],\n",
       "        [4.3982],\n",
       "        [2.8007],\n",
       "        [1.4499],\n",
       "        [2.6059],\n",
       "        [3.7368],\n",
       "        [3.8883],\n",
       "        [3.7774],\n",
       "        [3.6878],\n",
       "        [5.0985],\n",
       "        [4.3982],\n",
       "        [5.1540],\n",
       "        [5.6937],\n",
       "        [3.5114],\n",
       "        [2.6624],\n",
       "        [1.2017],\n",
       "        [1.5204],\n",
       "        [3.9940],\n",
       "        [3.4200],\n",
       "        [2.8007],\n",
       "        [5.1540],\n",
       "        [3.0285],\n",
       "        [2.4100],\n",
       "        [3.4177],\n",
       "        [4.2557],\n",
       "        [2.6930],\n",
       "        [2.5189],\n",
       "        [2.6351],\n",
       "        [1.4499],\n",
       "        [5.6937],\n",
       "        [3.0285],\n",
       "        [3.2044],\n",
       "        [4.5651],\n",
       "        [5.0374],\n",
       "        [1.4036],\n",
       "        [2.9307],\n",
       "        [4.0598],\n",
       "        [2.6059],\n",
       "        [3.5114],\n",
       "        [2.4100],\n",
       "        [3.2044],\n",
       "        [1.4255],\n",
       "        [2.4311],\n",
       "        [2.4027],\n",
       "        [3.6952],\n",
       "        [4.9921],\n",
       "        [3.7368],\n",
       "        [2.6624],\n",
       "        [3.4177],\n",
       "        [4.5651],\n",
       "        [1.4255],\n",
       "        [1.4609],\n",
       "        [2.9459],\n",
       "        [3.4361],\n",
       "        [4.8719],\n",
       "        [3.8883],\n",
       "        [1.2017],\n",
       "        [4.2557],\n",
       "        [5.0374],\n",
       "        [2.4311],\n",
       "        [1.4609]])}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set[0][1].edata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "#\n",
    "# Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n",
    "# SPDX-License-Identifier: Apache-2.0\n",
    "\n",
    "import dgl\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "\n",
    "def set_random_seed(seed=0):\n",
    "    \"\"\"Set random seed.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    seed : int\n",
    "        Random seed to use. Default to 0.\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "\n",
    "def collate_molgraphs(data):\n",
    "    \"\"\"Batching a list of datapoints for dataloader.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : list of 4-tuples.\n",
    "        Each tuple is for a single datapoint, consisting of\n",
    "        a SMILES, a DGLGraph, all-task labels and a binary\n",
    "        mask indicating the existence of labels.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    smiles : list\n",
    "        List of smiles\n",
    "    bg : DGLGraph\n",
    "        The batched DGLGraph.\n",
    "    labels : Tensor of dtype float32 and shape (B, T)\n",
    "        Batched datapoint labels. B is len(data) and\n",
    "        T is the number of total tasks.\n",
    "    \"\"\"\n",
    "    smiles, graphs, labels = map(list, zip(*data))\n",
    "\n",
    "    bg = dgl.batch(graphs)\n",
    "    bg.set_n_initializer(dgl.init.zero_initializer)\n",
    "    bg.set_e_initializer(dgl.init.zero_initializer)\n",
    "    labels = torch.stack(labels, dim=0)\n",
    "\n",
    "    return smiles, bg, labels\n",
    "\n",
    "def load_model(args):\n",
    "    if args['model'] == 'SchNet':\n",
    "        from dgllife.model import SchNetPredictor\n",
    "        model = SchNetPredictor(node_feats=args['node_feats'],\n",
    "                                hidden_feats=args['hidden_feats'],\n",
    "                                predictor_hidden_feats=args['predictor_hidden_feats'],\n",
    "                                n_tasks=args['n_tasks'])\n",
    "\n",
    "    if args['model'] == 'MGCN':\n",
    "        from dgllife.model import MGCNPredictor\n",
    "        model = MGCNPredictor(feats=args['feats'],\n",
    "                              n_layers=args['n_layers'],\n",
    "                              predictor_hidden_feats=args['predictor_hidden_feats'],\n",
    "                              n_tasks=args['n_tasks'])\n",
    "\n",
    "    if args['model'] == 'MPNN':\n",
    "        from dgllife.model import MPNNPredictor\n",
    "        model = MPNNPredictor(node_in_feats=args['node_in_feats'],\n",
    "                              edge_in_feats=args['edge_in_feats'],\n",
    "                              node_out_feats=args['node_out_feats'],\n",
    "                              edge_hidden_feats=args['edge_hidden_feats'],\n",
    "                              n_tasks=args['n_tasks'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=train_set,batch_size=24,collate_fn=collate_molgraphs)\n",
    "# val_loader = DataLoader(dataset=val_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dgllife.model import SchNetPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SchNetPredictor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "bg = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "bg = bg[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = bg.ndata.pop('n_feat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'node_type': tensor([ 6,  8,  6, 16,  6,  6,  8,  8,  6,  6,  6,  8,  6,  6,  6,  6,  8,  6,\n",
       "         6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  7,  6,  6,  6,  6,  6,  8,  6,\n",
       "         7,  6,  6,  6,  6,  6,  6,  6,  6,  6,  7,  6,  6,  7,  6,  8,  6,  6,\n",
       "         6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  8,  6,  6,  6,  8,  6,  8,\n",
       "         6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  8,  6,  6,  6,\n",
       "         6,  8,  6,  6,  6,  6,  7,  6,  6,  6,  6,  6,  6,  6,  6,  8,  8,  6,\n",
       "         6,  8,  6,  7,  6,  6,  6,  6,  8,  8,  6,  6,  6,  8,  8,  6,  6,  8,\n",
       "         7,  6,  6,  6,  6,  8,  6,  6,  6,  8,  6,  7,  6,  6,  6,  7,  6,  6,\n",
       "         8,  6,  6,  6,  6,  6,  6,  8,  6,  6,  7,  6,  6,  6,  6,  6,  6,  7,\n",
       "         6,  7,  6,  8,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  8,  6,  6,  8,\n",
       "         6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  8,  6,  6,  6,  8,\n",
       "         8,  6,  6,  6,  6,  6,  6,  7,  6,  8,  6,  6,  6,  8,  6,  8,  6,  6,\n",
       "         8,  6,  6,  7,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  8,  6,  7,\n",
       "         6,  6,  8,  6,  6,  8])}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bg.ndata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1., 0.,  ..., 0., 1., 1.],\n",
       "        [0., 0., 0.,  ..., 1., 0., 0.],\n",
       "        [0., 1., 0.,  ..., 0., 1., 3.],\n",
       "        ...,\n",
       "        [0., 1., 0.,  ..., 0., 1., 2.],\n",
       "        [0., 1., 0.,  ..., 1., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 1., 1.]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd = megnet[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['id', 'desc', 'formula', 'e_hull', 'gap pbe', 'mu_b', 'elastic anisotropy', 'bulk modulus', 'shear modulus', 'atoms', 'e_form'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dd.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['lattice_mat', 'coords', 'elements', 'abc', 'angles', 'cartesian', 'props'])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dd[\"atoms\"].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame(dd[\"atoms\"][\"coords\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.dataloading import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jarvis.core.atoms import Atoms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "structure = Atoms.from_dict(dd[\"atoms\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 5.39076238, 5.16244463, ..., 2.51134294, 4.5880922 ,\n",
       "        2.86475125],\n",
       "       [5.39076238, 0.        , 4.40974077, ..., 7.56552437, 6.01936939,\n",
       "        5.40159774],\n",
       "       [5.16244463, 4.40974077, 0.        , ..., 7.62887609, 6.46981477,\n",
       "        7.16837045],\n",
       "       ...,\n",
       "       [2.51134294, 7.56552437, 7.62887609, ..., 0.        , 5.60125545,\n",
       "        3.06735942],\n",
       "       [4.5880922 , 6.01936939, 6.46981477, ..., 5.60125545, 0.        ,\n",
       "        5.235826  ],\n",
       "       [2.86475125, 5.40159774, 7.16837045, ..., 3.06735942, 5.235826  ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "structure.raw_distance_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def atoms_to_distance(atom):\n",
    "    structure = Atoms.from_dict(atom)\n",
    "    return torch.tensor(structure.raw_distance_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_interaction_graph(d, cutoff):\n",
    "    \n",
    "    n_interactions = ((d <= cutoff)*(d>0)).sum()\n",
    "    \n",
    "    \n",
    "    edge_index = torch.zeros((n_interactions, 2), dtype=int)\n",
    "    edge_weight = torch.zeros((n_interactions,))\n",
    "    \n",
    "    cnt = 0\n",
    "    for i in range(d.shape[0]):\n",
    "        for j in range(d.shape[1]):\n",
    "            \n",
    "            if 0 < d[i,j] <= cutoff:\n",
    "                \n",
    "                edge_index[cnt] = torch.tensor([i,j])\n",
    "                edge_weight[cnt] = d[i,j]\n",
    "                cnt += 1\n",
    "                \n",
    "    return edge_index, edge_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/holywater2/2023/_Reproduce', '/home/holywater2/.conda/envs/porous/lib/python310.zip', '/home/holywater2/.conda/envs/porous/lib/python3.10', '/home/holywater2/.conda/envs/porous/lib/python3.10/lib-dynload', '', '/home/holywater2/.conda/envs/porous/lib/python3.10/site-packages', '/home/holywater2/.conda/envs/porous/lib/python3.10/site-packages/mpmath-1.2.1-py3.10.egg']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "# sys.path.insert(0, \"/home/holywater2/2023/porousequivariantnetworks/code/\")\n",
    "# sys.path.insert(0, \"/home/holywater2/2023/porousequivariantnetworks/\")\n",
    "print(sys.path)\n",
    "# sys.path.insert(0, \"../porousequivariantnetworks/code/models\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "from models.schnet import SchNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.ZeoliteData import get_zeolite, get_data_pore, get_data_graph, get_data_megnet\n",
    "from utils.dataloading import get_data, get_graph_data\n",
    "\n",
    "import numpy\n",
    "numpy.set_printoptions(threshold=10_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_zeolite('MOR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ref': array([[ 1,  1,  1],\n",
       "        [-1, -1,  1],\n",
       "        [ 1, -1, -1],\n",
       "        [-1,  1, -1],\n",
       "        [-1, -1, -1],\n",
       "        [ 1,  1, -1],\n",
       "        [-1,  1,  1],\n",
       "        [ 1, -1,  1],\n",
       "        [ 1,  1,  1],\n",
       "        [-1, -1,  1],\n",
       "        [ 1, -1, -1],\n",
       "        [-1,  1, -1],\n",
       "        [-1, -1, -1],\n",
       "        [ 1,  1, -1],\n",
       "        [-1,  1,  1],\n",
       "        [ 1, -1,  1]]),\n",
       " 'tra': array([[0. , 0. , 0. ],\n",
       "        [0. , 0. , 0.5],\n",
       "        [0. , 0. , 0. ],\n",
       "        [0. , 0. , 0.5],\n",
       "        [0. , 0. , 0. ],\n",
       "        [0. , 0. , 0.5],\n",
       "        [0. , 0. , 0. ],\n",
       "        [0. , 0. , 0.5],\n",
       "        [0.5, 0.5, 0. ],\n",
       "        [0.5, 0.5, 0.5],\n",
       "        [0.5, 0.5, 0. ],\n",
       "        [0.5, 0.5, 0.5],\n",
       "        [0.5, 0.5, 0. ],\n",
       "        [0.5, 0.5, 0.5],\n",
       "        [0.5, 0.5, 0. ],\n",
       "        [0.5, 0.5, 0.5]]),\n",
       " 'l': array([18.256, 20.534,  7.542]),\n",
       " 'X': array([[0.3057, 0.0736, 0.0435],\n",
       "        [0.3028, 0.3106, 0.0437],\n",
       "        [0.415 , 0.121 , 0.75  ],\n",
       "        [0.415 , 0.277 , 0.75  ],\n",
       "        [0.6943, 0.9264, 0.5435],\n",
       "        [0.6972, 0.6894, 0.5437],\n",
       "        [0.585 , 0.879 , 0.25  ],\n",
       "        [0.585 , 0.723 , 0.25  ],\n",
       "        [0.3057, 0.9264, 0.9565],\n",
       "        [0.3028, 0.6894, 0.9563],\n",
       "        [0.415 , 0.879 , 0.25  ],\n",
       "        [0.415 , 0.723 , 0.25  ],\n",
       "        [0.6943, 0.0736, 0.4565],\n",
       "        [0.6972, 0.3106, 0.4563],\n",
       "        [0.585 , 0.121 , 0.75  ],\n",
       "        [0.585 , 0.277 , 0.75  ],\n",
       "        [0.6943, 0.9264, 0.9565],\n",
       "        [0.6972, 0.6894, 0.9563],\n",
       "        [0.3057, 0.0736, 0.4565],\n",
       "        [0.3028, 0.3106, 0.4563],\n",
       "        [0.6943, 0.0736, 0.0435],\n",
       "        [0.6972, 0.3106, 0.0437],\n",
       "        [0.3057, 0.9264, 0.5435],\n",
       "        [0.3028, 0.6894, 0.5437],\n",
       "        [0.8057, 0.5736, 0.0435],\n",
       "        [0.8028, 0.8106, 0.0437],\n",
       "        [0.915 , 0.621 , 0.75  ],\n",
       "        [0.915 , 0.777 , 0.75  ],\n",
       "        [0.1943, 0.4264, 0.5435],\n",
       "        [0.1972, 0.1894, 0.5437],\n",
       "        [0.085 , 0.379 , 0.25  ],\n",
       "        [0.085 , 0.223 , 0.25  ],\n",
       "        [0.8057, 0.4264, 0.9565],\n",
       "        [0.8028, 0.1894, 0.9563],\n",
       "        [0.915 , 0.379 , 0.25  ],\n",
       "        [0.915 , 0.223 , 0.25  ],\n",
       "        [0.1943, 0.5736, 0.4565],\n",
       "        [0.1972, 0.8106, 0.4563],\n",
       "        [0.085 , 0.621 , 0.75  ],\n",
       "        [0.085 , 0.777 , 0.75  ],\n",
       "        [0.1943, 0.4264, 0.9565],\n",
       "        [0.1972, 0.1894, 0.9563],\n",
       "        [0.8057, 0.5736, 0.4565],\n",
       "        [0.8028, 0.8106, 0.4563],\n",
       "        [0.1943, 0.5736, 0.0435],\n",
       "        [0.1972, 0.8106, 0.0437],\n",
       "        [0.8057, 0.4264, 0.5435],\n",
       "        [0.8028, 0.1894, 0.5437]]),\n",
       " 'Xo': array([[0.2811, 0.    , 0.    ],\n",
       "        [0.3268, 0.0795, 0.25  ],\n",
       "        [0.3757, 0.0924, 0.9243],\n",
       "        [0.2391, 0.1223, 0.9992],\n",
       "        [0.3253, 0.3089, 0.25  ],\n",
       "        [0.25  , 0.25  , 0.    ],\n",
       "        [0.3757, 0.3058, 0.9242],\n",
       "        [0.    , 0.4005, 0.25  ],\n",
       "        [0.0906, 0.3009, 0.25  ],\n",
       "        [0.    , 0.2013, 0.25  ]]),\n",
       " 'tX': array([0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 0, 1, 0, 1,\n",
       "        0, 1, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 0, 1,\n",
       "        0, 1, 0, 1])}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref = data['ref'] # reflections\n",
    "tra = data['tra'] # translations\n",
    "l = data['l'] # scale of the unit cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "atoms, hoa, X, A, d, X_pore, A_pore, d_pore, pore = get_data(l)\n",
    "# X is positon\n",
    "# A is adjacent matrix\n",
    "# d is distance matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges, idx1, idx2, idx2_oh = get_graph_data(A, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4123"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(atoms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpnn = SchNet(d).to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, testloader, trainloader = get_data_graph(atoms, hoa, edges, bs=32, sub_lim=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x7f8522c2f5b0>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = next(iter(testloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ...,\n",
       "          [1],\n",
       "          [0],\n",
       "          [0]],\n",
       " \n",
       "         [[0],\n",
       "          [0],\n",
       "          [1],\n",
       "          ...,\n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       " \n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ...,\n",
       "          [1],\n",
       "          [1],\n",
       "          [1]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0],\n",
       "          [0],\n",
       "          [0],\n",
       "          ...,\n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       " \n",
       "         [[0],\n",
       "          [1],\n",
       "          [0],\n",
       "          ...,\n",
       "          [0],\n",
       "          [0],\n",
       "          [0]],\n",
       " \n",
       "         [[1],\n",
       "          [1],\n",
       "          [0],\n",
       "          ...,\n",
       "          [0],\n",
       "          [0],\n",
       "          [0]]]),\n",
       " tensor([[[3.1075],\n",
       "          [3.1224],\n",
       "          [3.1264],\n",
       "          ...,\n",
       "          [3.2343],\n",
       "          [3.0959],\n",
       "          [3.1073]],\n",
       " \n",
       "         [[3.1075],\n",
       "          [3.1224],\n",
       "          [3.1264],\n",
       "          ...,\n",
       "          [3.2343],\n",
       "          [3.0959],\n",
       "          [3.1073]],\n",
       " \n",
       "         [[3.1075],\n",
       "          [3.1224],\n",
       "          [3.1264],\n",
       "          ...,\n",
       "          [3.2343],\n",
       "          [3.0959],\n",
       "          [3.1073]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[3.1075],\n",
       "          [3.1224],\n",
       "          [3.1264],\n",
       "          ...,\n",
       "          [3.2343],\n",
       "          [3.0959],\n",
       "          [3.1073]],\n",
       " \n",
       "         [[3.1075],\n",
       "          [3.1224],\n",
       "          [3.1264],\n",
       "          ...,\n",
       "          [3.2343],\n",
       "          [3.0959],\n",
       "          [3.1073]],\n",
       " \n",
       "         [[3.1075],\n",
       "          [3.1224],\n",
       "          [3.1264],\n",
       "          ...,\n",
       "          [3.2343],\n",
       "          [3.0959],\n",
       "          [3.1073]]]),\n",
       " tensor([45.9360, 40.0254, 41.7774, 41.7200, 44.7223, 44.0056, 44.8421, 38.8548,\n",
       "         46.6058, 43.9404, 44.2273, 43.6094, 45.3932, 42.6424, 46.1127, 42.0403,\n",
       "         39.5525, 43.0062, 40.4921, 42.1065, 42.3839, 47.8156, 44.9950, 42.3127,\n",
       "         47.8737, 45.4289, 45.2298, 42.7357, 44.2002, 44.6925, 41.0769, 42.9491],\n",
       "        dtype=torch.float64)]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainloss, testloss = mpnn.fit(trainloader, testloader, 200, scale_loss=False, opt=optim.AdamW,opt_kwargs={'lr':0.001}, crit_kwargs={'delta':1.0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parser = argparse.ArgumentParser()\n",
    "\n",
    "#parser.add_argument('-n', '--name', type=str)\n",
    "# parser.add_argument('-m', '--model_type', choices=['pore', 'equi','megnet','cgcnn','schnet'], type=str)\n",
    "# parser.add_argument('-p', '--prop_train', type=float)\n",
    "# parser.add_argument('-r', '--repetitions', type=int)\n",
    "# parser.add_argument('-i', '--initial_repetition', type=int, default=1)\n",
    "\n",
    "# args = parser.parse_args()\n",
    "\n",
    "\n",
    "#model_name = args.name\n",
    "# print(args)\n",
    "# for i in range(args.repetitions):\n",
    "\n",
    "# print('started repetition', i)\n",
    "\n",
    "# model_name = f'model_{i+1+args.initial_repetition}'\n",
    "\n",
    "data_dir = f'model_data/{args.prop_train}/{args.model_type}/{model_name}/'\n",
    "\n",
    "os.makedirs(data_dir)\n",
    "\n",
    "print('started!')\n",
    "\n",
    "\n",
    "data = get_zeolite('MOR')\n",
    "\n",
    "ref = data['ref'] # reflections\n",
    "tra = data['tra'] # translations\n",
    "l = data['l'] # scale of the unit cell\n",
    "\n",
    "# specific for MOR\n",
    "atoms, hoa, X, A, d, X_pore, A_pore, d_pore, pore = get_data(l)\n",
    "\n",
    "edges, idx1, idx2, idx2_oh = get_graph_data(A, d)\n",
    "\n",
    "if args.model_type == 'pore':\n",
    "\n",
    "    edges_sp, idx1_sp, idx2_sp, idx2_oh_sp = get_graph_data(A_pore, d_pore)\n",
    "    edges_ps, idx1_ps, idx2_ps, idx2_oh_ps = get_graph_data(A_pore.T, d_pore.T)\n",
    "\n",
    "    mpnn = MPNNPORE(idx1.to('cuda'), idx2.to('cuda'), idx2_oh.to('cuda'), X, X_pore, ref, tra,\n",
    "                    idx1_sp.to('cuda'), idx2_sp.to('cuda'), idx2_oh_sp.to('cuda'), \n",
    "                    idx1_ps.to('cuda'), idx2_ps.to('cuda'), idx2_oh_ps.to('cuda'),\n",
    "                    hid_size=[8]*6, site_emb_size=8, edge_emb_size=8, mlp_size=24,\n",
    "                    centers=10, mx_d=6, width=1, pool='sum').to('cuda')\n",
    "    _, testloader, trainloader = get_data_pore(atoms, hoa, edges, pore, edges_sp, edges_ps, bs=32, sub_lim=12, p=args.prop_train)\n",
    "\n",
    "elif args.model_type == 'equi':\n",
    "\n",
    "    mpnn = MPNN(idx1.to('cuda'), idx2.to('cuda'), idx2_oh.to('cuda'), X, ref, tra,\n",
    "                    hid_size=[8]*6, site_emb_size=8, edge_emb_size=8, mlp_size=24,\n",
    "                    centers=10, mx_d=6, width=1, pool='sum').to('cuda')\n",
    "\n",
    "\n",
    "    _, testloader, trainloader = get_data_graph(atoms, hoa, edges, bs=32, sub_lim=12, p=args.prop_train)\n",
    "\n",
    "elif args.model_type == 'megnet':\n",
    "\n",
    "    mpnn = MEGNet(idx1.to('cuda'), idx2.to('cuda')).to('cuda')\n",
    "\n",
    "\n",
    "    _, testloader, trainloader = get_data_megnet(atoms, hoa, edges, bs=32, sub_lim=12, p=args.prop_train)\n",
    "\n",
    "\n",
    "elif args.model_type == 'cgcnn':\n",
    "\n",
    "    mpnn = CGCNN(idx1.to('cuda'), idx2.to('cuda')).to('cuda')\n",
    "\n",
    "\n",
    "    _, testloader, trainloader = get_data_graph(atoms, hoa, edges, bs=32, sub_lim=12, p=args.prop_train)\n",
    "    \n",
    "\n",
    "elif args.model_type == 'schnet':\n",
    "    \n",
    "    mpnn = SchNet(d).to('cuda')\n",
    "\n",
    "    \n",
    "    _, testloader, trainloader = get_data_graph(atoms, hoa, edges, bs=32, sub_lim=12, p=args.prop_train)\n",
    "\n",
    "print('starting fitting!')\n",
    "trainloss, testloss = mpnn.fit(trainloader, testloader, 200, scale_loss=False, opt=optim.AdamW,opt_kwargs={'lr':0.001}, crit_kwargs={'delta':1.0})\n",
    "\n",
    "\n",
    "print('done fitting!')\n",
    "\n",
    "\n",
    "torch.save(mpnn.state_dict(), f'{data_dir}/model.pth')\n",
    "\n",
    "np.save(f'{data_dir}/tr_loss.npy', trainloss)\n",
    "\n",
    "np.save(f'{data_dir}/te_loss.npy', testloss)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "porous",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
